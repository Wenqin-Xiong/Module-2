{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train_data.csv'\n",
    "t1 = time.time()\n",
    "data = pandas.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Seriously cannot stand this McDonald's. They N...</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>-112.205020</td>\n",
       "      <td>33.509597</td>\n",
       "      <td>['Burgers', 'Fast Food', 'Restaurants']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Tom Colicchio's Craftsteak</td>\n",
       "      <td>Amazing food, truly excellent best lobster bis...</td>\n",
       "      <td>2013-03-07</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-115.169751</td>\n",
       "      <td>36.102918</td>\n",
       "      <td>['Steakhouses', 'Restaurants', 'Cheesesteaks',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Fishman Lobster Clubhouse Restaurant</td>\n",
       "      <td>This was my second time here, and the seafood ...</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>-79.300795</td>\n",
       "      <td>43.824234</td>\n",
       "      <td>['Seafood', 'Restaurants', 'Chinese', 'Live/Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bonjour Brioche</td>\n",
       "      <td>Long story short.\\n\\nBunch of rude, heartless,...</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>-79.346287</td>\n",
       "      <td>43.659795</td>\n",
       "      <td>['Breakfast &amp; Brunch', 'French', 'Restaurants']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dilly's Deli</td>\n",
       "      <td>We grabbed some dinner here last night before ...</td>\n",
       "      <td>2010-09-28</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>-111.945365</td>\n",
       "      <td>33.422175</td>\n",
       "      <td>['Caterers', 'Sandwiches', 'Event Planning &amp; S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                  name  \\\n",
       "0      1                            McDonald's   \n",
       "1      5            Tom Colicchio's Craftsteak   \n",
       "2      5  Fishman Lobster Clubhouse Restaurant   \n",
       "3      1                       Bonjour Brioche   \n",
       "4      4                          Dilly's Deli   \n",
       "\n",
       "                                                text        date       city  \\\n",
       "0  Seriously cannot stand this McDonald's. They N...  2014-12-29   Glendale   \n",
       "1  Amazing food, truly excellent best lobster bis...  2013-03-07  Las Vegas   \n",
       "2  This was my second time here, and the seafood ...  2015-11-24    Toronto   \n",
       "3  Long story short.\\n\\nBunch of rude, heartless,...  2016-12-20    Toronto   \n",
       "4  We grabbed some dinner here last night before ...  2010-09-28      Tempe   \n",
       "\n",
       "    longitude   latitude                                         categories  \n",
       "0 -112.205020  33.509597            ['Burgers', 'Fast Food', 'Restaurants']  \n",
       "1 -115.169751  36.102918  ['Steakhouses', 'Restaurants', 'Cheesesteaks',...  \n",
       "2  -79.300795  43.824234  ['Seafood', 'Restaurants', 'Chinese', 'Live/Ra...  \n",
       "3  -79.346287  43.659795    ['Breakfast & Brunch', 'French', 'Restaurants']  \n",
       "4 -111.945365  33.422175  ['Caterers', 'Sandwiches', 'Event Planning & S...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5=data[data[\"stars\"]==5]\n",
    "data_txt5=data_5[\"text\"]\n",
    "data_txt5=data_txt5[0:50]\n",
    "data_txt5.to_csv(\"5 star.csv\",sep=\",\")\n",
    "\n",
    "data_1=data[data[\"stars\"]==1]\n",
    "data_txt1=data_1[\"text\"]\n",
    "data_txt1=data_txt1[3:53]\n",
    "data_txt1.to_csv(\"1 star.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-87990e6c1de6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-acfc476cd06e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_modeltxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_modeltxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_modeltxt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_modeltxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstop_delete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data_modeltxt=data[\"text\"]\n",
    "data_modeltxt=data_modeltxt[0:1000]\n",
    "data_modeltxt.head()\n",
    "    \n",
    "def stop_delete(sentence):\n",
    "    sentence=sentence.lower().split()\n",
    "    sen=[word for word in sentence if not word in stop]\n",
    "    sen_re=np.array([])\n",
    "    for j in sen:\n",
    "        word_re=re.sub('[^a-zA-Z]','', j)\n",
    "        if word_re != \"\":\n",
    "            sen_re=np.append(sen_re,word_re)\n",
    "    return sen_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_delete' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-150852dbe680>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstop_delete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_modeltxt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_delete' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    txt=stop_delete(data_modeltxt[i])\n",
    "    txt=[stem.stem(word) for word in txt]\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
