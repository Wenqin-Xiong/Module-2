{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train_data.csv'\n",
    "t1 = time.time()\n",
    "data = pandas.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreviews=10000\n",
    "#nreviews=data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt=data[\"text\"]\n",
    "data_txt=data_txt[0:nreviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words(\"english\"))\n",
    "stop_neg=[\"wasn't\",'wasn',\"couldn't\",'couldn',\n",
    "          \"wouldn't\",'wouldn',\"shouldn't\",'shouldn',\"shan't\",\n",
    "          \"haven't\",\"hasn't\",\"hadn't\",\"hadn'\",\n",
    "          \"don't\",'don',\"doesn't\",'doesn',\"didn't\",\n",
    "          \"needn't\",'needn','no','nor',\n",
    "          \"isn't\",'isn',\"aren't\",\"weren't\",'weren',\"won't\"]\n",
    "stop_revised=[w for w in stop if not w in stop_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_delete(sentence):\n",
    "    sentence=sentence.lower().split(\" \")\n",
    "    sen=[word for word in sentence if not word in stop]\n",
    "    sen_re=np.array([])\n",
    "    for j in sen:\n",
    "        word_re=re.sub('[^a-zA-Z]','', j)\n",
    "        if word_re != \"\":\n",
    "            sen_re=np.append(sen_re,word_re)\n",
    "    return sen_re\n",
    "\n",
    "def stop_delete_re(sentence):\n",
    "    sentence=sentence.lower().split(\" \")\n",
    "    sen=[word for word in sentence if not word in stop_revised]\n",
    "    sen_re=np.array([])\n",
    "    for j in sen:\n",
    "        if j in stop_neg:\n",
    "            sen_re=np.append(sen_re,\"neg_w\")\n",
    "        else:\n",
    "            word_re=re.sub('[^a-zA-Z]','', j)\n",
    "            if word_re != \"\":\n",
    "                sen_re=np.append(sen_re,word_re)\n",
    "    return sen_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "\n",
    "#clear text\n",
    "document=[]\n",
    "document_re=[]\n",
    "for sen in data_txt:\n",
    "    txt=stop_delete(sen)\n",
    "    txt_re=stop_delete_re(sen)\n",
    "    \n",
    "    txt=[stem.stem(word) for word in txt]\n",
    "    txt_re=[stem.stem(word) for word in txt_re]\n",
    "    \n",
    "    document.append(txt)\n",
    "    document_re.append(txt_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency, threshold=min_freq\n",
    "frequency=defaultdict(int)\n",
    "#intensity\n",
    "freq_pos=defaultdict(int)\n",
    "freq_neg=defaultdict(int)\n",
    "\n",
    "score=data[\"stars\"]\n",
    "\n",
    "for i in range(nreviews):\n",
    "    sen=document[i]\n",
    "    for word in sen:\n",
    "        frequency[word] += 1\n",
    "        if score[i] > 3:\n",
    "            freq_pos[word] += 1\n",
    "        elif score[i] < 3:\n",
    "            freq_neg[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=[[word for word in sen if frequency[word] > min_freq] for sen in document]\n",
    "document_re=[[word for word in sen if frequency[word] > min_freq] for sen in document_re]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict={}\n",
    "for word in list(frequency):\n",
    "    if word not in list(freq_pos):\n",
    "        freq_pos[word]=0\n",
    "    if word not in list(freq_neg):\n",
    "        freq_neg[word]=0    \n",
    "    if frequency[word] <= min_freq:\n",
    "        del frequency[word]\n",
    "        del freq_pos[word]\n",
    "        del freq_neg[word]\n",
    "    else:\n",
    "        frequency_dict[word]=[frequency[word],freq_pos[word],freq_neg[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w=data[0:nreviews]\n",
    "data_w=data_w.drop(\"text\", axis=1)\n",
    "\n",
    "text=[]\n",
    "\n",
    "for i in range(nreviews):\n",
    "    sen=document_re[i]\n",
    "    txt=\"\"\n",
    "    for w in sen:\n",
    "        txt=txt+w+\" \"\n",
    "    text.append(txt)\n",
    "\n",
    "data_w[\"text\"]=text    \n",
    "        \n",
    "data_w.to_csv(\"data_cleaned.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('document.csv', 'w', newline=\"\") as myfile:\n",
    "    writer = csv.writer(myfile)\n",
    "    writer.writerows(document)\n",
    "    \n",
    "with open('document_re.csv', 'w', newline=\"\") as myfile:\n",
    "    writer = csv.writer(myfile)\n",
    "    writer.writerows(document_re)\n",
    "\n",
    "with open('frequency.csv', 'w', newline=\"\") as myfile:\n",
    "    writer = csv.writer(myfile)\n",
    "    writer.writerow([\"word\",\"count\",\"pos\",\"neg\"])\n",
    "    for key, value in frequency_dict.items():\n",
    "        writer.writerow([key, value[0],value[1],value[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"document.csv\", 'r') as filein: \n",
    "    reader = csv.reader(filein)\n",
    "    document = list(list(rec) for rec in csv.reader(filein, delimiter=',')) \n",
    "    \n",
    "freq_std = pandas.read_csv('frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word  count   pos  neg   pos_std   neg_std\n",
      "0  serious    156    79   62  0.506410  0.397436\n",
      "1   cannot    142    88   34  0.619718  0.239437\n",
      "2    stand    200   102   67  0.510000  0.335000\n",
      "3    never   1274   668  474  0.524333  0.372057\n",
      "4      get   3558  1981  944  0.556773  0.265318\n"
     ]
    }
   ],
   "source": [
    "freq_std[\"pos_std\"]=freq_std[\"pos\"]/freq_std[\"count\"]\n",
    "freq_std[\"neg_std\"]=freq_std[\"neg\"]/freq_std[\"count\"]\n",
    "print(freq_std.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450      fantast\n",
      "460          gem\n",
      "818          yum\n",
      "533      perfect\n",
      "816      delight\n",
      "608       highli\n",
      "658     outstand\n",
      "879         cozi\n",
      "203       delici\n",
      "59          amaz\n",
      "61         excel\n",
      "212      favorit\n",
      "79        awesom\n",
      "280         glad\n",
      "905      homemad\n",
      "107        yummi\n",
      "909        fabul\n",
      "537    perfectli\n",
      "914        sampl\n",
      "590         rich\n",
      "726     knowledg\n",
      "253       wonder\n",
      "314       creami\n",
      "105         love\n",
      "583         duck\n",
      "69         great\n",
      "389         beat\n",
      "290         spot\n",
      "639       welcom\n",
      "301        juici\n",
      "         ...    \n",
      "501       tender\n",
      "360         stuf\n",
      "233        enjoy\n",
      "667      varieti\n",
      "597        split\n",
      "675      authent\n",
      "649           th\n",
      "428         must\n",
      "259       indian\n",
      "484        thank\n",
      "176      absolut\n",
      "854     charlott\n",
      "445     cocktail\n",
      "286         town\n",
      "813        vegan\n",
      "653       plenti\n",
      "250         vega\n",
      "469     mushroom\n",
      "206        spici\n",
      "516      everyth\n",
      "28           lol\n",
      "512      environ\n",
      "451         wine\n",
      "846       desert\n",
      "730      outdoor\n",
      "391       brunch\n",
      "235        roast\n",
      "374       spring\n",
      "944        broth\n",
      "528       attent\n",
      "Name: word, Length: 100, dtype: object\n",
      "423         worst\n",
      "40        terribl\n",
      "753       horribl\n",
      "580            aw\n",
      "130          rude\n",
      "721        apolog\n",
      "72           wast\n",
      "405       hostess\n",
      "802         dirti\n",
      "11          sorri\n",
      "676          poor\n",
      "162         manag\n",
      "588          bare\n",
      "779         charg\n",
      "915       mediocr\n",
      "308         bland\n",
      "175         phone\n",
      "731        overpr\n",
      "148          told\n",
      "51          minut\n",
      "139           min\n",
      "49           mess\n",
      "598          bill\n",
      "637       ridicul\n",
      "585         money\n",
      "552        receiv\n",
      "710        suppos\n",
      "689         soggi\n",
      "784          paid\n",
      "711    understand\n",
      "          ...    \n",
      "662          ladi\n",
      "455        waiter\n",
      "814         plain\n",
      "638         spend\n",
      "407           sat\n",
      "600      waitress\n",
      "0         serious\n",
      "15           hate\n",
      "432       tonight\n",
      "847         speak\n",
      "798       continu\n",
      "149         tough\n",
      "171          leav\n",
      "550            ok\n",
      "216        gotten\n",
      "463          issu\n",
      "845         state\n",
      "145         arriv\n",
      "604        unless\n",
      "752           low\n",
      "369           put\n",
      "569         notic\n",
      "863          what\n",
      "557         figur\n",
      "785          girl\n",
      "262      deliveri\n",
      "151         guest\n",
      "366          walk\n",
      "3           never\n",
      "50           wait\n",
      "Name: word, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#base dict, threshold=base_n\n",
    "base_num=100\n",
    "\n",
    "base_p=freq_std.sort_values(\"pos_std\",ascending=0)\n",
    "base_pos=base_p[\"word\"][0:base_num]\n",
    "\n",
    "base_n=freq_std.sort_values(\"neg_std\",ascending=0)\n",
    "base_neg=base_n[\"word\"][0:base_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word  count  pos  neg   pos_std   neg_std\n",
      "423    worst    218   14  181  0.064220  0.830275\n",
      "40   terribl    260   27  205  0.103846  0.788462\n",
      "753  horribl    221   23  174  0.104072  0.787330\n",
      "580       aw    106   12   79  0.113208  0.745283\n",
      "130     rude    198   24  147  0.121212  0.742424\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
