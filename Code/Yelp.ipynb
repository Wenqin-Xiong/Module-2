{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train_data.csv'\n",
    "t1 = time.time()\n",
    "data = pandas.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Seriously cannot stand this McDonald's. They N...</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>-112.205020</td>\n",
       "      <td>33.509597</td>\n",
       "      <td>['Burgers', 'Fast Food', 'Restaurants']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Tom Colicchio's Craftsteak</td>\n",
       "      <td>Amazing food, truly excellent best lobster bis...</td>\n",
       "      <td>2013-03-07</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>-115.169751</td>\n",
       "      <td>36.102918</td>\n",
       "      <td>['Steakhouses', 'Restaurants', 'Cheesesteaks',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Fishman Lobster Clubhouse Restaurant</td>\n",
       "      <td>This was my second time here, and the seafood ...</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>-79.300795</td>\n",
       "      <td>43.824234</td>\n",
       "      <td>['Seafood', 'Restaurants', 'Chinese', 'Live/Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bonjour Brioche</td>\n",
       "      <td>Long story short.\\n\\nBunch of rude, heartless,...</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>-79.346287</td>\n",
       "      <td>43.659795</td>\n",
       "      <td>['Breakfast &amp; Brunch', 'French', 'Restaurants']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dilly's Deli</td>\n",
       "      <td>We grabbed some dinner here last night before ...</td>\n",
       "      <td>2010-09-28</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>-111.945365</td>\n",
       "      <td>33.422175</td>\n",
       "      <td>['Caterers', 'Sandwiches', 'Event Planning &amp; S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                  name  \\\n",
       "0      1                            McDonald's   \n",
       "1      5            Tom Colicchio's Craftsteak   \n",
       "2      5  Fishman Lobster Clubhouse Restaurant   \n",
       "3      1                       Bonjour Brioche   \n",
       "4      4                          Dilly's Deli   \n",
       "\n",
       "                                                text        date       city  \\\n",
       "0  Seriously cannot stand this McDonald's. They N...  2014-12-29   Glendale   \n",
       "1  Amazing food, truly excellent best lobster bis...  2013-03-07  Las Vegas   \n",
       "2  This was my second time here, and the seafood ...  2015-11-24    Toronto   \n",
       "3  Long story short.\\n\\nBunch of rude, heartless,...  2016-12-20    Toronto   \n",
       "4  We grabbed some dinner here last night before ...  2010-09-28      Tempe   \n",
       "\n",
       "    longitude   latitude                                         categories  \n",
       "0 -112.205020  33.509597            ['Burgers', 'Fast Food', 'Restaurants']  \n",
       "1 -115.169751  36.102918  ['Steakhouses', 'Restaurants', 'Cheesesteaks',...  \n",
       "2  -79.300795  43.824234  ['Seafood', 'Restaurants', 'Chinese', 'Live/Ra...  \n",
       "3  -79.346287  43.659795    ['Breakfast & Brunch', 'French', 'Restaurants']  \n",
       "4 -111.945365  33.422175  ['Caterers', 'Sandwiches', 'Event Planning & S...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "GeocoderInsufficientPrivileges",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[1;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# pylint: disable=W0703\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    641\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 642\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGeocoderInsufficientPrivileges\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-19573c9cd759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgeolocator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"52.5, 13.37\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(location.address)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\u001b[0m in \u001b[0;36mreverse\u001b[1;34m(self, query, exactly_one, timeout, language)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.reverse: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         return self._parse_json(\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_geocoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         )\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupytor\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[1;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mERROR_CODE_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mGeocoderServiceError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mGeocoderInsufficientPrivileges\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(timeout=3, scheme='http') \n",
    "geolocator = geopy.geocoders.GoogleV3(timeout=3\n",
    "location = geolocator.reverse(\"52.5, 13.37\")\n",
    "#print(location.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5=data[data[\"stars\"]==5]\n",
    "data_txt5=data_5[\"text\"]\n",
    "data_txt5=data_txt5[0:50]\n",
    "data_txt5.to_csv(\"5 star.csv\",sep=\",\")\n",
    "\n",
    "data_1=data[data[\"stars\"]==1]\n",
    "data_txt1=data_1[\"text\"]\n",
    "data_txt1=data_txt1[3:53]\n",
    "data_txt1.to_csv(\"1 star.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nreviews=1000\n",
    "#nreviews=data.shape[0]\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "data_modeltxt=data[\"text\"]\n",
    "data_modeltxt=data_modeltxt[0:nreviews]\n",
    "data_modeltxt.head()\n",
    "    \n",
    "def stop_delete(sentence):\n",
    "    sentence=sentence.lower().split()\n",
    "    sen=[word for word in sentence if not word in stop]\n",
    "    sen_re=np.array([])\n",
    "    for j in sen:\n",
    "        word_re=re.sub('[^a-zA-Z]','', j)\n",
    "        if word_re != \"\":\n",
    "            sen_re=np.append(sen_re,word_re)\n",
    "    return sen_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "\n",
    "document=[];\n",
    "for i in data_modeltxt:\n",
    "    txt=stop_delete(i)\n",
    "    txt=[stem.stem(word) for word in txt]\n",
    "    document.append(txt);\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency=defaultdict(int)\n",
    "for txt in document:\n",
    "    for word in txt:\n",
    "        frequency[word] += 1\n",
    "\n",
    "document = [[word for word in txt if frequency[word] > 1] for txt in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('document_txt.csv', 'w', newline=\"\") as myfile:\n",
    "    writer = csv.writer(myfile)\n",
    "    writer.writerows(document)\n",
    "\n",
    "with open('frequency_txt.csv', 'w', newline=\"\") as myfile:\n",
    "    writer = csv.writer(myfile)\n",
    "    for key, value in frequency.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"document_txt.csv\", 'r') as filein: \n",
    "    reader = csv.reader(filein)\n",
    "    document = list(list(rec) for rec in csv.reader(filein, delimiter=',')) \n",
    "    \n",
    "with open(\"frequency_txt.csv\", 'r') as filein: \n",
    "    reader = csv.reader(filein)\n",
    "    frequency = dict(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary\n",
    "dictionary = corpora.Dictionary(document)\n",
    "dictionary.save('yelpword.dict')\n",
    "#list to corpus\n",
    "corpus = [dictionary.doc2bow(txt) for txt in document]\n",
    "corpora.MmCorpus.serialize('yelpreview.mm', corpus)\n",
    "document = corpora.MmCorpus('yelpreview.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel(corpus=document, id2word=dictionary, num_topics=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50,\n",
       "  '0.017*\"good\" + 0.014*\"bar\" + 0.013*\"wir\" + 0.013*\"new\" + 0.013*\"chico\" + 0.011*\"coffe\" + 0.011*\"place\" + 0.011*\"get\" + 0.010*\"die\" + 0.010*\"food\"'),\n",
       " (41,\n",
       "  '0.015*\"good\" + 0.012*\"order\" + 0.012*\"food\" + 0.012*\"pizza\" + 0.011*\"place\" + 0.010*\"got\" + 0.010*\"would\" + 0.009*\"it\" + 0.009*\"friend\" + 0.008*\"tri\"'),\n",
       " (84,\n",
       "  '0.017*\"place\" + 0.015*\"good\" + 0.012*\"servic\" + 0.010*\"food\" + 0.009*\"great\" + 0.009*\"time\" + 0.008*\"best\" + 0.008*\"well\" + 0.007*\"like\" + 0.007*\"order\"'),\n",
       " (37,\n",
       "  '0.019*\"good\" + 0.011*\"drink\" + 0.010*\"soup\" + 0.010*\"realli\" + 0.010*\"order\" + 0.009*\"eat\" + 0.009*\"servic\" + 0.009*\"much\" + 0.009*\"bar\" + 0.008*\"place\"'),\n",
       " (14,\n",
       "  '0.020*\"food\" + 0.015*\"good\" + 0.014*\"burger\" + 0.013*\"great\" + 0.011*\"get\" + 0.009*\"littl\" + 0.008*\"order\" + 0.008*\"place\" + 0.007*\"chees\" + 0.007*\"servic\"')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
